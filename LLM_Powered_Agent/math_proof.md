Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models   https://arxiv.org/pdf/2411.12580 
  https://lauraruis.github.io/2024/11/10/if.html

https://aclanthology.org/2024.naacl-long.102/

https://arxiv.org/pdf/2404.12534v1

https://arxiv.org/pdf/2312.04556

https://arxiv.org/pdf/2301.13867

https://www.mdpi.com/2227-7102/14/7/698

https://www.ijimai.org/journal/sites/default/files/2024-02/ijimai8_5_7.pdf

https://link.springer.com/article/10.1007/s40751-024-00155-8

Teaching Large Language Models to Reason with Reinforcement Learning https://arxiv.org/abs/2403.04642

Symbolic Learning Enables Self-Evolving Agents https://arxiv.org/abs/2406.18532

Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B: A Technical Report https://arxiv.org/abs/2406.07394

DESIGN OF CHAIN-OF-THOUGHT IN MATH PROBLEM SOLVING https://arxiv.org/abs/2309.11054

Mathematical Capabilities of ChatGPT https://arxiv.org/abs/2301.13867

Investigating the Effectiveness of ChatGPT in Mathematical Reasoning and Problem Solving: Evidence from the Vietnamese National High School Graduation Examination https://arxiv.org/abs/2306.06331

Can Large Language Models Understand Symbolic Graphics Programs? https://github.com/sgp-bench/sgp-bench
